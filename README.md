# ğŸµ Music Generation

This repository contains tools and scripts to prepare, analyze, and preprocess music data for fine-tuning a generative model. The project is structured into several stages:

* `data_preparation`: Prepares datasets for training.
* `finetuning_audiocraft`: Fine-tunes the [AudioCraft](https://github.com/facebookresearch/audiocraft) model.
* `finetuning_audio_ldm`: Fine-tunes the [AudioLDM](https://github.com/haoheliu/AudioLDM-training-finetuning) model.
* `SLURM`: SLURM batch jobs for training and inference.
* `testing`: Evaluation tools for generated outputs.

---

## ğŸ“ Project Structure

```
MusicGeneration/
â”œâ”€â”€ data_preparation/
â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”œâ”€â”€ analyze_single.py
â”‚   â”œâ”€â”€ chunk_audio.py
â”‚   â”œâ”€â”€ demucs.py
â”‚   â”œâ”€â”€ demucs_instruments.py
â”‚   â”œâ”€â”€ generate_mels.py
â”‚   â”œâ”€â”€ metadata_adder.py
â”‚   â”œâ”€â”€ metadata_generation.py
â”‚   â””â”€â”€ resample.py
â”œâ”€â”€ finetuning_audiocraft/
â”‚   â””â”€â”€ (Modified AudioCraft repo and custom scripts)
â”œâ”€â”€ finetuning_audio_ldm/
â”‚   â””â”€â”€ (Modified AudioLDM repo and custom scripts)
â”œâ”€â”€ SLURM/
â”‚   â”œâ”€â”€ slurm_inference_musicgen
â”‚   â”œâ”€â”€ slurm_inference_pretrained
â”‚   â””â”€â”€ slurm_musicgen_text
â”œâ”€â”€ testing/
â”‚   â”œâ”€â”€ CLAP/
â”‚   â”œâ”€â”€â”€â”€â”€â”€ clap_testing.py
â”‚   â”œâ”€â”€ FAD/
â”‚   â””â”€â”€â”€â”€â”€â”€ fad_testing.py
â””â”€â”€ README.md
```

---

## ğŸš€ Data Preparation

The data preparation pipeline involves the following stages:

1. **Source Separation** using [Demucs](https://github.com/facebookresearch/demucs)
2. **Resampling** to 32kHz
3. **Chunking** into consistent-length audio segments
4. **Feature Extraction** (e.g., mel spectrograms)
5. **Musical Analysis** (BPM, key, etc.)
6. **Metadata Enrichment** (automated & manual)

---

## ğŸ› ï¸ Finetuning AudioCraft

### ğŸ“‚ `finetuning_audiocraft/`

This folder contains a cloned and modified version of the [AudioCraft](https://github.com/facebookresearch/audiocraft) repository, adapted for our custom training pipeline.

#### ğŸ”§ Key Features:

* Custom datasets
* Training on pre-chunked and labeled `.wav` pairs

> Make sure to follow AudioCraftâ€™s [installation instructions](https://github.com/facebookresearch/audiocraft#installation), and then replace or integrate your files with this folder.

---
## ğŸ› ï¸ Finetuning AudioLDM

### ğŸ“‚ `audio_ldm_fine_tune/`

This folder contains a cloned and modified version of the [AudioLDM](https://github.com/haoheliu/AudioLDM-training-finetuning) repository, adapted for our custom training pipeline.

#### ğŸ”§ Key Features:

* Added multi conditioning

---
## ğŸ§µ SLURM Scripts

### ğŸ“‚ `SLURM/`

Contains SLURM batch job scripts used for launching training and inference on compute clusters.

#### ğŸ” `slurm_inference_musicgen`

* Runs inference using musicgen finetunned checkpoint

#### ğŸ” `slurm_inference_pretrained`

* Runs inference using pretrained model.

#### ğŸ” `slurm_text_musicgen`

* AudioLDM Finetunning script.

#### ğŸ” `slurm_audio_ldm`

* AudioLDM Finetunning script.
#### ğŸ” `slurm_inference_ldm`

* AudioLDM Finetunning script.
Make sure to adjust paths, job names, and resource allocations as needed for your cluster.

---

## ğŸ§ª Testing
# ğŸ§ Frechet Audio Distance (FAD) Evaluation

This project evaluates the similarity between two sets of audio files using **Frechet Audio Distance (FAD)** with the **VGGish model**.

FAD is commonly used to measure the quality of generated audio against a reference dataset (e.g., ground truth). A **lower FAD score indicates better quality** and higher similarity to the reference.

---

## ğŸ“¦ Step 1: Clone the Repository

```bash
git clone https://github.com/gudgud96/frechet-audio-distance.git
cd frechet-audio-distance
```
## ğŸ Step 2: Set Up Python Environment
Make sure you are using Python 3.8â€“3.10. Then install the required dependencies:
```bash
pip install -r requirements.txt
```
## ğŸ“ Step 3: Prepare Your Audio Data

#### Organize your .wav files in the following structure:

path/to/project/
â”œâ”€â”€ target/
â”‚   â””â”€â”€ target1.wav
â”œâ”€â”€ pre_trained/
    â””â”€â”€ generated1.wav

    The target/ folder contains reference audio.

    The pre_trained/ folder contains generated audio for evaluation.
## ğŸ§  Step 4: Run FAD Evaluation
```
python fad_testing.py
```

### ğŸ“ `testing/CLAP/clap_testing.py`

This script evaluates genre similarity between generated audio and a set of text prompts using the [CLAP model](https://huggingface.co/laion/clap-htsat-fused).

#### ğŸ” What it does:

* Loads a pretrained CLAP audio-text model
* Embeds a list of **genre text prompts** (e.g., `"rock"`, `"pop"`, `"disco"`)
* Iterates over `.wav` files in a directory and computes audio embeddings
* Measures cosine similarity with text embeddings
* Outputs CSV results with genre predictions

#### ğŸ“‚ Example Usage

```python
audio_dir = "/path/to/generated/audio"
```

```bash
python testing/CLAP/clap_testing.py
```

#### ğŸ“‹ Output Example

| file             | best\_genre | best\_score | score\_disco | score\_rock | score\_pop |
| ---------------- | ----------- | ----------- | ------------ | ----------- | ---------- |
| track\_01.wav    | rock        | 0.873       | 0.65         | 0.87        | 0.71       |
| sample\_beat.wav | pop         | 0.812       | 0.63         | 0.75        | 0.81       |

---

## ğŸ§° Setup

Install dependencies:

```bash
pip install librosa soundfile numpy pandas tqdm python-dotenv openai
```

Install Demucs:

```bash
pip install demucs
```

---

## ğŸ“ˆ Example Pipeline

1. Place raw `.wav`/`.mp3` files in a folder.
2. Run Demucs:

   ```bash
   python demucs.py
   ```
3. Resample output:

   ```bash
   python resample.py
   ```
4. Chunk the audio:

   ```bash
   python chunk_audio.py
   ```
5. Generate mel spectrograms:

   ```bash
   python generate_mels.py
   ```
6. Analyze musical features:

   ```bash
   python analyzer.py
   ```
7. Generate metadata:

   ```bash
   python metadata_generation.py
   ```

---

## ğŸ‘¥ Contributors

* Mohamed Youssef
* Selim Elbindary

